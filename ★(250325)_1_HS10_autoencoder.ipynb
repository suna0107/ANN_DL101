{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGAhcTNSfyFmw1R05RFNCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suna0107/ANN_DL101/blob/main/%E2%98%85(250325)_1_HS10_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[HS CODE Representation]**\n",
        "\n",
        "- AutoEncoder 기반 Feature Extraction\n",
        "- 100개차원 → 64개차원 → 32개 차원 → 64개차원 → 100개차원\n",
        "- 32개 차원의 값을 추출"
      ],
      "metadata": {
        "id": "OQIg0YLsyVWL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wTZOktLjsQhi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 준비"
      ],
      "metadata": {
        "id": "PaVSXEViuYnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. HS Code Embedding Layer (10자리 × 10차원 = 100차원)\n",
        "\n"
      ],
      "metadata": {
        "id": "PiE9bf22VeGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.(def) 엑셀에서 HS Code 불러오기 및 데이터 전처리"
      ],
      "metadata": {
        "id": "AMlwQRY3X2vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 엑셀 파일 경로\n",
        "file_path = \"/content/HS_CODE_PROCESSED_kr_en_final.xlsx\"\n",
        "\n",
        "# ✅ 엑셀 로드\n",
        "df = pd.read_excel(file_path, dtype=str)\n",
        "\n",
        "# ✅ 'HS_CODE' 열을 리스트로 저장\n",
        "# 컬럼명을 제외한 실제 데이터만 가져오기\n",
        "hs_codes = df[\"HS_CODE\"].iloc[1:].tolist()  # 또는 df[\"HS_CODE\"].dropna().tolist()"
      ],
      "metadata": {
        "id": "SQL0JZ9uzZRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. (def정의) HS Code를 정수 리스트 -> PyTorch 텐서로 변환\n",
        "\n",
        "\n",
        "7283940512\" → [7,2,8,3,9,4,0,5,1,2]"
      ],
      "metadata": {
        "id": "zRqhjbKK_lJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_hs_code(hs_codes):\n",
        "    processed_codes = []\n",
        "    for hs in hs_codes:\n",
        "        digits = [int(digit) for digit in hs]\n",
        "        processed_codes.append(digits)\n",
        "    return torch.tensor(processed_codes, dtype=torch.long) # PyTorch 텐서로 변환"
      ],
      "metadata": {
        "id": "scpPnM582OxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수 실행\n",
        "hs_tensor = preprocess_hs_code(hs_codes)\n",
        "hs_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg2xz3VbXkvS",
        "outputId": "d5649fab-ab84-40a3-b999-8eacbc7052be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16820, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Autoencoder 모델\n",
        "\n",
        "- HSAutoencoder 클래스 설정 : HS Code를 Autoencoder를 이용해 학습하고, 32차원의 Latent Representation을 추출하는 모델\n",
        "\n"
      ],
      "metadata": {
        "id": "aG37geuKZG2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)  # 재현성을 위해 랜덤시드 설정\n",
        "class HSAutoencoder(nn.Module):\n",
        "    def __init__(self, vocab_size=10, embed_dim=10, input_dim=100, hidden_dim=64, latent_dim=32):\n",
        "        super(HSAutoencoder, self).__init__() # __init__(생성자) = 네트워크 구조 정의\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim) # 1. HS Code Embedding Layer (10자리 × 10차원 = 100차원)\n",
        "        self.encoder = nn.Sequential(       # 2️. Encoder: 100 → 64 → 32\n",
        "            nn.Linear(input_dim, hidden_dim),# 100 → 64\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, latent_dim), # 64 → 32\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(      # 3. Decoder: 32 → 64 → 100/ 잠재 공간(32차원)을 다시 100차원으로 복원\n",
        "            nn.Linear(latent_dim, hidden_dim),# 32 → 64\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, input_dim),# 64 → 100\n",
        "            nn.Sigmoid() # Sigmoid()를 사용 → 출력값을 0~1 범위로 정규화\n",
        "        )\n",
        "\n",
        "    def forward(self, x): # 4. forward() → 순전파(입력 → 인코딩 → 디코딩)\n",
        "        x = self.embedding(x) # HS Code를 벡터화\n",
        "        x = x.view(x.size(0), -1) # 100차원으로 펼침 (batch_size, 100)\n",
        "        encoded = self.encoder(x) # 인코딩 (100 → 32)\n",
        "        decoded = self.decoder(encoded) # 디코딩 (32 → 100)\n",
        "        return decoded, encoded # 디코딩된 결과(100차원) 와 32차원 잠재 표현을 반환"
      ],
      "metadata": {
        "id": "JeIr8wuR1d7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.DataLoader 설정\n",
        " - 배치단위로 데이터 분할하여 train data 준비"
      ],
      "metadata": {
        "id": "WabEJEZObXh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터준비\n",
        "file_path = \"/content/HS_CODE_PROCESSED_kr_en_final.xlsx\"  # 엑셀 파일 경로\n",
        "hs_tensor = preprocess_hs_code(hs_codes)\n",
        "hs_codes = df[\"HS_CODE\"].tolist()\n",
        "\n",
        "#2. 배치단위로 데이터 준비 : dataset\n",
        "#2-1. hs_tensor를 PyTorch에서 사용할 수 있도록 변환 = 모델 입력 데이터\n",
        "# hs_tensor는 원본 데이터(텐서), dataset은 PyTorch 모델 학습을 위한 포맷\n",
        "batch_size = 32\n",
        "dataset = TensorDataset(hs_tensor)\n",
        "\n",
        "#2. 배치 단위로 데이터 분할\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "## batch_size=32 : 한 번에 32개씩 모델에 입력\n",
        "## shuffle=True: 데이터 순서를 랜덤\n",
        "# train_loader : dataset에서 데이터를 32개씩 랜덤하게 구성하여 학습\n",
        "\n"
      ],
      "metadata": {
        "id": "zhNZ7yZt1iX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. 모델 학습(Training)"
      ],
      "metadata": {
        "id": "TtjrZjpJgVST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 모델 초기화\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HSAutoencoder().to(device) # 모델을 device에 할당 = 모델을 GPU 또는 CPU에 배치\n",
        "criterion = nn.MSELoss() #손실 함수(MSE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam Optimizer 설정\n",
        "\n",
        "hs_tensor = hs_tensor.to(device) #  hs_tensor 입력 데이터를 GPU/CPU로 이동"
      ],
      "metadata": {
        "id": "xZlPtfwhADvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습루프 설정\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs): # 100번(num_epochs=100) 반복하며 모델을 학습\n",
        "    optimizer.zero_grad() # 기존의 그래디언트 초기화\n",
        "    reconstructed, latent = model(hs_tensor) # 모델 순전파 수행\n",
        "\n",
        "# `hs_tensor`를 모델 출력(reconstructed)과 동일한 100차원으로 변환\n",
        "    hs_tensor_embedded = model.embedding(hs_tensor)  #(batch_size, 10, 10)\n",
        "    hs_tensor_embedded = hs_tensor_embedded.view(hs_tensor_embedded.size(0), -1)  #(batch_size, 100)\n",
        "\n",
        "# MSE 손실 계산\n",
        "    loss = criterion(reconstructed, hs_tensor_embedded.float())\n",
        "    loss.backward() # 역전파 수행\n",
        "    optimizer.step() # 가중치 업데이트\n",
        "    if epoch % 10 == 0: # 10 에포크마다 손실 값 출력\n",
        "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecAZlwuq_h-P",
        "outputId": "ca7d13b5-b9e3-42c7-d06c-bc87ef827104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/100], Loss: 1.4987\n",
            "Epoch [10/100], Loss: 1.4188\n",
            "Epoch [20/100], Loss: 1.1885\n",
            "Epoch [30/100], Loss: 0.9826\n",
            "Epoch [40/100], Loss: 0.9459\n",
            "Epoch [50/100], Loss: 0.9263\n",
            "Epoch [60/100], Loss: 0.9076\n",
            "Epoch [70/100], Loss: 0.8878\n",
            "Epoch [80/100], Loss: 0.8653\n",
            "Epoch [90/100], Loss: 0.8394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "-  현재 손실값이 0.8 정도로 수렴\n",
        "\n",
        "- 일반적으로 0.1 ~ 1.0 사이면 괜찮은 복원 성능일 가능성이 높음\n"
      ],
      "metadata": {
        "id": "hCvf6R5O0j6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-1. 학습 손실 줄이기 위한 방안\n",
        "\n",
        "(1) 학습률 조정 : lr=0.001 → 0.0005 -> 0.00025\n",
        "손실 : 0.8 -> 0.66 -> 0.56\n",
        "\n",
        "- 최적의 학습률로 loss 적정한 값 설정 중요\n",
        "- 최종 학습률 : 0.0005 로 설정\n",
        "\n"
      ],
      "metadata": {
        "id": "-pZjdVTW1La9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습률 조정 : 0.0005로 감소시킴\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "# 학습률 조정 : 0.00025로 감소시킴\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.00025)"
      ],
      "metadata": {
        "id": "TNFQxF8t_kob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습루프 설정\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs): # 100번(num_epochs=100) 반복하며 모델을 학습\n",
        "    optimizer.zero_grad() # 기존의 그래디언트 초기화\n",
        "    reconstructed, latent = model(hs_tensor) # 모델 순전파 수행\n",
        "\n",
        "# `hs_tensor`를 모델 출력(reconstructed)과 동일한 100차원으로 변환\n",
        "    hs_tensor_embedded = model.embedding(hs_tensor)  #(batch_size, 10, 10)\n",
        "    hs_tensor_embedded = hs_tensor_embedded.view(hs_tensor_embedded.size(0), -1)  #(batch_size, 100)\n",
        "\n",
        "# MSE 손실 계산\n",
        "    loss = criterion(reconstructed, hs_tensor_embedded.float())\n",
        "    loss.backward() # 역전파 수행\n",
        "    optimizer.step() # 가중치 업데이트\n",
        "    if epoch % 10 == 0: # 10 에포크마다 손실 값 출력\n",
        "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbIrDw45_j7V",
        "outputId": "8a9b9a8d-0039-4d49-f19d-f27147b8c1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/100], Loss: 0.8106\n",
            "Epoch [10/100], Loss: 0.7948\n",
            "Epoch [20/100], Loss: 0.7804\n",
            "Epoch [30/100], Loss: 0.7669\n",
            "Epoch [40/100], Loss: 0.7539\n",
            "Epoch [50/100], Loss: 0.7414\n",
            "Epoch [60/100], Loss: 0.7291\n",
            "Epoch [70/100], Loss: 0.7162\n",
            "Epoch [80/100], Loss: 0.7032\n",
            "Epoch [90/100], Loss: 0.6906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. HS Code의 32차원 Representation"
      ],
      "metadata": {
        "id": "txCZISBHA4EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HS Code의 32차원 Representation 확인 : latent_vectors\n",
        "_, latent_vectors = model(hs_tensor) # model(hs_tensor) Autoencoder의 forward() 함수가 실행\n",
        "# 출력값은 (복원된 데이터, 32차원 Representation)\n",
        "## 언더스코어(_)는 복원된 데이터(Decoder 출력)를 말고, 오직 latent_vectors만 저장\n",
        "\n",
        "latent_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tETlORI8A1YH",
        "outputId": "b12a23b1-c6ae-47ea-c2fb-8e9888a18902",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16820, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n🔹 HS Code Embedding Representation (32차원):\")\n",
        "# PyTorch Tensor → NumPy 배열 변환 출력 가능하게 만듦\n",
        "latent_vectors_np = latent_vectors.detach().cpu().numpy()\n",
        "latent_vectors_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUq3PAhuPDB-",
        "outputId": "3dcfb86c-c734-4419-8ff9-f41203c40009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 HS Code Embedding Representation (32차원):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.9277961,  0.       , 14.768636 , ...,  1.226641 ,  9.8383045,\n",
              "        13.410532 ],\n",
              "       [ 4.7087317,  0.       , 11.197586 , ...,  0.9700618,  6.2565813,\n",
              "        11.431807 ],\n",
              "       [ 5.4289045,  0.       ,  7.855844 , ...,  1.9067473,  5.978879 ,\n",
              "        10.671864 ],\n",
              "       ...,\n",
              "       [ 2.666396 ,  0.       , 10.368039 , ...,  1.8679845,  8.0265465,\n",
              "         6.0774355],\n",
              "       [ 2.66522  ,  0.       , 12.301055 , ...,  2.238477 ,  8.579593 ,\n",
              "         8.481747 ],\n",
              "       [ 2.6851647,  0.       , 11.8448925, ...,  1.9224209,  8.362972 ,\n",
              "         8.700762 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s-VZM892PC2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- PyTorch 파일 (.pt) → PyTorch 모델에서 사용할 때 편리"
      ],
      "metadata": {
        "id": "L1JoDItAN2L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(latent_vectors, \"hs_latent_vectors.pt\")\n"
      ],
      "metadata": {
        "id": "GLGM-HUwNH9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CSV 파일 (to_csv) → 다른 데이터와 연계할 때 가장 쉬움"
      ],
      "metadata": {
        "id": "H4jJEiJ5N5Qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas DataFrame으로 변환\n",
        "df_latent = pd.DataFrame(latent_vectors_np)\n",
        "df_latent.shape\n",
        "# CSV 파일로 저장\n",
        "df_latent.to_csv(\"hs_latent_vectors.csv\", index=False)"
      ],
      "metadata": {
        "id": "ZjLVJGVVOBUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- hs_code열 추가 : 다른 데이터와 merge하기 위한 데이터"
      ],
      "metadata": {
        "id": "7vfLImG2-kZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 오토인코더 결과 벡터 로딩\n",
        "ae_vecs = pd.read_csv(\"/content/hs_latent_vectors.csv\")  # 각 행 = 32차원 latent 벡터\n",
        "\n",
        "# 2. 원래 학습에 사용한 HS 코드 리스트\n",
        "hs_code_list = pd.read_excel(\"/content/HS_CODE_PROCESSED_kr_en_final.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "id": "o5QRdkKE-kMF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hs_code_list.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AChBb8BB_uyn",
        "outputId": "d208b101-dd7b-4bef-9139-11ac852db643"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16820 entries, 0 to 16819\n",
            "Data columns (total 18 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   4                             16820 non-null  int64  \n",
            " 1   6                             16820 non-null  int64  \n",
            " 2   8                             16820 non-null  int64  \n",
            " 3   10                            16820 non-null  int64  \n",
            " 4   HS_CODE                       16820 non-null  int64  \n",
            " 5   제XX류                          16820 non-null  object \n",
            " 6   제XXXX.XX호                     16710 non-null  object \n",
            " 7   Chapter                       16820 non-null  int64  \n",
            " 8   Subheading                    16710 non-null  float64\n",
            " 9   국문                            16820 non-null  object \n",
            " 10  영문                            16820 non-null  object \n",
            " 11  Referenced_HS                 16820 non-null  object \n",
            " 12  Referenced_HS_Description_EN  378 non-null    object \n",
            " 13  Referenced_HS_EN              16820 non-null  object \n",
            " 14  Referenced_HS_Description     365 non-null    object \n",
            " 15  SBERT_Input                   16820 non-null  object \n",
            " 16  Token_Count                   16820 non-null  int64  \n",
            " 17  SBERT_Input_EN                16820 non-null  object \n",
            "dtypes: float64(1), int64(7), object(10)\n",
            "memory usage: 2.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 벡터에 HS 코드 정보 붙이기\n",
        "ae_vecs['HS_CODE_10'] = hs_code_list['HS_CODE']\n",
        "ae_vecs['HS_CODE_6'] = ae_vecs['HS_CODE_10'].astype(str).str[:6]\n",
        "\n",
        "# 4. 결과 저장\n",
        "ae_vecs.to_csv(\"hs_ae_vectors_with_code.csv\", index=False)"
      ],
      "metadata": {
        "id": "i80_mTHZ-3vV"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}